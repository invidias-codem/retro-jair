// stem.js
import { useState, useEffect, useRef } from "react";
import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import { FontAwesomeIcon } from '@fortawesome/react-fontawesome';
import {
  faFlask, faSun, faMoon, faCog, faTimes, faClipboard,
  faPaperPlane, faChevronDown, faSpinner, faPaperclip, faPencilAlt,
} from '@fortawesome/free-solid-svg-icons';

import ReactMarkdown, { MarkdownHooks } from 'react-markdown';
import remarkGfm from 'remark-gfm';
import remarkMath from 'remark-math';
import rehypeKatex from 'rehype-katex';
import 'katex/dist/katex.min.css';

import "./chat.css";

const fileToGenerativePart = async (file) => {
    const base64EncodedDataPromise = new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        if (reader.result) {
          resolve(reader.result.toString().split(',')[1]);
        } else {
          reject(new Error("Failed to read file."));
        }
      };
      reader.onerror = (error) => reject(error);
      reader.readAsDataURL(file);
    });
    try {
        const data = await base64EncodedDataPromise;
        return {
          inlineData: { data, mimeType: file.type },
        };
    } catch (error) {
        console.error("Error in fileToGenerativePart:", error);
        throw error;
    }
};

const StemChat = () => {
    // --- Core State ---
    const [isModalOpen, setIsModalOpen] = useState(false);
    const [messages, setMessages] = useState([]);
    const [userInput, setUserInput] = useState("");
    const [chat, setChat] = useState(null); // For text-based chat (gemini-1.5-flash-latest)
    const [dedicatedImageGenModel, setDedicatedImageGenModel] = useState(null); // For gemini-2.0-flash-preview-image-generation
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState(null);
    const [subscription, setSubscription] = useState("free");
    const [remainingInteractions, setRemainingInteractions] = useState(10);
    const [isUserScrolled, setIsUserScrolled] = useState(false);
    const [showScrollToBottom, setShowScrollToBottom] = useState(false);
    const [notification, setNotification] = useState(null);

    // --- STEM Specific State ---
    const [theme, setTheme] = useState("light");
    const [fileAttachment, setFileAttachment] = useState(null);
    const [isNotepadOpen, setIsNotepadOpen] = useState(false);
    const [isGeneratingImage, setIsGeneratingImage] = useState(false);

    // --- Refs ---
    const inputRef = useRef(null);
    const messagesEndRef = useRef(null);
    const messagesContainerRef = useRef(null);
    const fileInputRef = useRef(null);

    const stemConfig = {
        name: "Professor AI",
        icon: faFlask,
        initialPrompt: `You are Professor AI, a knowledgeable and patient STEM tutor. Your primary role is to provide clear textual explanations for Science, Technology, Engineering, and Math topics. Use Markdown for formatting and LaTeX for math. If a user's query suggests a visual is needed (e.g., "draw a plant cell"), the system will separately attempt to generate an image using a specialized image model. You should focus on the textual explanation related to the user's query. If an image is successfully generated by the system, it will be displayed alongside your text.`,
        initialResponse: "Hello! I'm Professor AI. Ask me any STEM question, or describe a diagram you'd like to see (e.g., 'Can you draw a simple electric circuit and explain it?'). I'll provide explanations, and the system will try to generate visuals if appropriate!",
        placeholder: "Ask a STEM question or describe a diagram...",
        outOfCreditsMessage: "Upgrade for unlimited STEM help!",
        interactionName: "Lessons",
        buttonText: "Ask Professor AI",
        containerClass: "stem-chat-container",
        messageClass: "stem-message",
        messageBubbleClass: "stem-message-bubble",
        buttonClass: "stem-button",
        headerClass: "stem-header",
        inputClass: "stem-input",
        loaderClass: "stem-loading",
        modalClass: "stem-modal",
        modalContentClass: "stem-modal-content",
        messagesClass: "stem-messages",
        defaultTheme: "light",
        copyIcon: faClipboard,
        copyTooltip: "Copy explanation/formula",
        logoClass: "stem-logo",
        logoIconClass: "stem-logo-icon",
        logoTextClass: "stem-logo-text",
        controlsClass: "stem-controls",
        subscriptionBadgeClass: "stem-subscription-badge",
        closeButtonClass: "stem-close-button",
        errorMessageClass: "stem-error-message",
        footerClass: "stem-footer",
        sendButtonClass: "stem-send-button"
    };
    const currentMode = stemConfig;

    useEffect(() => {
        setTheme(currentMode.defaultTheme);
    }, [currentMode.defaultTheme]);

    useEffect(() => {
        const initializeAPI = () => {
            const apiKey = process.env.REACT_APP_GEMINI_API;
            if (!apiKey) { setError("API key not found."); return null; }
            try { return new GoogleGenerativeAI(apiKey); }
            catch (err) { setError("Failed to initialize Gemini API."); console.error(err); return null; }
        };

        const initializeModels = async () => {
            setLoading(true); setError(null); setMessages([]); setChat(null); setDedicatedImageGenModel(null);
            const genAI = initializeAPI();
            if (!genAI) { setLoading(false); return; }

            try {
                // Initialize the standard chat model
                const chatModelInstance = genAI.getGenerativeModel({ model: "gemini-1.5-flash-latest" });
                const newChat = chatModelInstance.startChat({
                    history: [
                        { role: "user", parts: [{ text: currentMode.initialPrompt }] },
                        { role: "model", parts: [{ text: currentMode.initialResponse }] },
                    ],
                    generationConfig: { temperature: 0.6, topK: 40, topP: 0.9, maxOutputTokens: 4096 },
                    safetySettings: [
                        { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                        { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                        { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                        { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                    ],
                });
                setChat(newChat);

                // Initialize the dedicated image generation model
                // *** Using the specific model ID you mentioned was in your original working /draw command ***
                const imageModelInstance = genAI.getGenerativeModel({ model: "gemini-2.0-flash-preview-image-generation" });
                setDedicatedImageGenModel(imageModelInstance);
                console.log("Dedicated image generation model initialized:", imageModelInstance ? "Success" : "Failed");

                setMessages([{ role: "model", text: currentMode.initialResponse, timestamp: Date.now() }]);
            } catch (err) {
                const errorMessage = `Failed to initialize AI models: ${err.message}. Check model names and API key permissions.`;
                setError(errorMessage);
                console.error("Model initialization error:", err);
            } finally { setLoading(false); }
        };
        initializeModels();
    }, [currentMode.initialPrompt, currentMode.initialResponse, currentMode.name]);


    const handleSendMessage = async () => {
        const textInput = userInput.trim();
        const currentFileAttachment = fileAttachment;

        if ((!textInput && !currentFileAttachment) || (subscription === "free" && remainingInteractions <= 0) || (!chat && !dedicatedImageGenModel) || loading) {
            if (!textInput && !currentFileAttachment) setError("Please type a message or attach a file.");
            else if ((!chat || !dedicatedImageGenModel) && !loading) setError("AI models are not ready. Please wait.");
            return;
        }

        setLoading(true);
        setError(null);
        let attemptImageGeneration = false;
        let imagePromptText = textInput; // Default to full input for image prompt

        const timestamp = Date.now();
        let userMessageDisplayText = textInput;

        if (textInput) {
            const imageRequestKeywords = ['draw', 'diagram', 'sketch', 'illustrate', 'visualize', 'picture of', 'show me a', 'generate an image of', 'what does.*look like'];
            for (const keyword of imageRequestKeywords) {
                const regex = new RegExp(`(?:${keyword}\\s*(?:of|a|an)?\\s*)(.+)$`, "i"); // Try to capture text after keyword
                const match = textInput.match(regex);
                if (match && match[1]) {
                    attemptImageGeneration = true;
                    imagePromptText = match[1].trim(); // Use the specific description
                    break;
                }
            }
            if (!attemptImageGeneration && imageRequestKeywords.some(keyword => new RegExp(keyword, "i").test(textInput))) {
                attemptImageGeneration = true; // If keyword present but no specific part matched, use full input
                imagePromptText = textInput;
            }
        }
        setIsGeneratingImage(attemptImageGeneration);

        let messagePartsForTextExplanation = [];
        if (textInput) messagePartsForTextExplanation.push({ text: textInput });

        if (currentFileAttachment) {
            if (!currentFileAttachment.type.startsWith("image/") || currentFileAttachment.size > 4 * 1024 * 1024) {
                 setError("Invalid or oversized file (max 4MB).");
                 setFileAttachment(null); if (fileInputRef.current) fileInputRef.current.value = "";
                 setLoading(false); setTimeout(() => setError(null), 3000);
                 return;
            }
            try {
                const filePart = await fileToGenerativePart(currentFileAttachment);
                messagePartsForTextExplanation.push(filePart);
                userMessageDisplayText += `\n[File: ${currentFileAttachment.name || 'Pasted Image'}]`;
            } catch (err) {
                setError("Error processing file.");
                setLoading(false); setFileAttachment(null); if (fileInputRef.current) fileInputRef.current.value = "";
                return;
            }
        }

        const newUserMessage = { role: "user", text: userMessageDisplayText, timestamp };
        setMessages(prevMessages => [...prevMessages, newUserMessage]);
        setUserInput(""); setFileAttachment(null);
        if (fileInputRef.current) fileInputRef.current.value = "";

        let generatedImageUrl = null;
        let botTextResponse = "";

        try {
            if (attemptImageGeneration && imagePromptText && dedicatedImageGenModel) {
                console.log(`Attempting image generation with dedicated model. Prompt: "${imagePromptText}"`);
                try {
                    const imageResult = await dedicatedImageGenModel.generateContent({
                        contents: [{ role: "user", parts: [{ text: imagePromptText }] }],
                        // Configuration based on your original /draw command for gemini-2.0-flash-preview-image-generation
                        generationConfig: {
                            responseModalities: ["TEXT", "IMAGE"], // Expecting it might give both as per your original code
                            temperature: 0.6, // Using values from your original /draw
                            topK: 40,
                            topP: 0.9,
                            maxOutputTokens: 1024, // May not need many tokens if only image focused
                        },
                        safetySettings: [
                            { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                            { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                            { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                            { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE },
                        ],
                    });

                    const imageResponseParts = imageResult?.response?.candidates?.[0]?.content?.parts;
                    console.log("Image model response parts:", imageResponseParts);

                    if (imageResponseParts && Array.isArray(imageResponseParts)) {
                        for (const part of imageResponseParts) {
                            if (part.inlineData?.data && part.inlineData?.mimeType?.startsWith("image/")) {
                                generatedImageUrl = `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
                                console.log("Image data extracted from dedicated model.");
                                // If the image model also provides relevant text, you could use it or append it.
                                // For now, we prioritize text from the main chat model.
                            } else if (part.text && !generatedImageUrl) {
                                // If image model returns text instead of/before an image (e.g. an error or comment)
                                console.log("Text from image model:", part.text)
                                // botTextResponse += (botTextResponse ? "\n\n" : "") + part.text; // Option: append this text
                            }
                        }
                    }
                    if (!generatedImageUrl) {
                        console.warn("Dedicated image model did not return image data as expected.");
                        // Potentially set a specific error or let the text model explain
                    }
                } catch (imgErr) {
                    console.error("Dedicated image generation API call failed:", imgErr);
                    setError(`Image generation failed: ${imgErr.message}`);
                }
            }

            // Always get text explanation from the main chat model
            if (chat && messagePartsForTextExplanation.length > 0) {
                const textResult = await chat.sendMessage(messagePartsForTextExplanation);
                const textResponseParts = textResult?.response?.candidates?.[0]?.content?.parts;
                if (textResponseParts && Array.isArray(textResponseParts)) {
                    textResponseParts.forEach(part => {
                        if (part.text) {
                            botTextResponse += (botTextResponse ? "\n\n" : "") + part.text;
                        }
                    });
                } else if (textResult?.response?.text) { // Fallback
                    botTextResponse = textResult.response.text();
                }
            }

            if (!botTextResponse && !generatedImageUrl) {
                botTextResponse = "I encountered an issue processing your request. Please try rephrasing.";
            } else if (generatedImageUrl && !botTextResponse) {
                botTextResponse = "Here is the visual you requested:";
            } else if (!generatedImageUrl && attemptImageGeneration && botTextResponse) {
                // If user asked for an image, but we didn't get one,
                // let the text response from the main model stand, as it might explain.
            }

            const newBotMessage = {
                role: "model",
                text: botTextResponse.trim(),
                imageUrl: generatedImageUrl,
                type: generatedImageUrl ? 'image_response' : 'text',
                timestamp: Date.now()
            };
            setMessages(prevMessages => [...prevMessages, newBotMessage]);

            if (subscription === "free") setRemainingInteractions(prev => Math.max(0, prev - 1));

        } catch (err) {
            console.error("Overall message sending/processing error:", err);
            let errorText = "An unexpected error occurred.";
            if (err.message?.includes("Candidate was blocked")) errorText = "Response blocked due to safety settings.";
            else if (err.message?.includes("quota")) errorText = "API quota exceeded.";
            else if (err.message) errorText = `Error: ${err.message}`;
            setError(errorText);
            setMessages(prevMessages => prevMessages.filter(msg => msg.timestamp !== timestamp));
        } finally {
            setLoading(false);
            setIsGeneratingImage(false);
            if (inputRef.current) inputRef.current.focus();
        }
    };

    // ... (handleCopyResponse, handlePaste, handleFileChange, triggerFileInput, toggleNotepad, scrolling, other handlers, ChatHeader, ScrollToBottomButton)
    // ... (These functions remain the same as your last provided version) ...

    const handleCopyResponse = async (msg) => {
        if (typeof ClipboardItem !== 'undefined' && msg.imageUrl) {
            try {
                const response = await fetch(msg.imageUrl);
                const blob = await response.blob();
                await navigator.clipboard.write([ new ClipboardItem({ [blob.type]: blob }) ]);
                showNotification("Image copied to clipboard");
            } catch (err) { console.error('Failed to copy image: ', err); showNotification("Failed to copy image"); }
        } else if (msg.text) {
            navigator.clipboard.writeText(msg.text)
                .then(() => showNotification("Text copied to clipboard"))
                .catch(err => { console.error('Failed to copy text: ', err); showNotification("Failed to copy text"); });
        } else { showNotification("Nothing to copy"); }
    };

    const handlePaste = (event) => {
        const items = event.clipboardData?.items;
        if (items) {
            for (const item of items) {
                if (item.kind === 'file' && item.type.startsWith('image/')) {
                    const file = item.getAsFile();
                    if (file) {
                        if (!file.type.startsWith("image/") || file.size > 4 * 1024 * 1024) {
                            showNotification("Pasted file is invalid or too large (max 4MB).");
                            event.preventDefault(); return;
                        }
                        event.preventDefault(); setFileAttachment(file);
                        showNotification(`Pasted image: ${file.name || 'image.png'}`);
                        setError(null); return;
                    }
                }
            }
        }
    };

    const handleFileChange = (event) => {
        const file = event.target.files[0];
        if (file) {
            if (file.type.startsWith("image/") && file.size <= 4 * 1024 * 1024) {
                setFileAttachment(file); showNotification(`Selected: ${file.name}`); setError(null);
            } else {
                showNotification("Please select an image file (PNG, JPG, etc.) up to 4MB.");
                event.target.value = ""; setFileAttachment(null);
            }
        }
    };

    const triggerFileInput = () => fileInputRef.current?.click();

    const toggleNotepad = () => {
        setIsNotepadOpen(!isNotepadOpen);
        showNotification(isNotepadOpen ? "Notepad closed" : "Notepad opened (Feature coming soon!)");
    };

    const scrollToBottom = () => {
        if (messagesEndRef.current) {
            messagesEndRef.current.scrollIntoView({ behavior: "smooth" });
            setShowScrollToBottom(false); setIsUserScrolled(false);
        }
    };

    useEffect(() => {
        if (!isUserScrolled && messagesContainerRef.current && messagesContainerRef.current.scrollHeight > messagesContainerRef.current.clientHeight) {
             scrollToBottom();
        }
    }, [messages, isUserScrolled]);

    const handleScroll = () => {
        if (messagesContainerRef.current) {
            const { scrollTop, scrollHeight, clientHeight } = messagesContainerRef.current;
            const isNearBottom = scrollHeight - clientHeight - scrollTop < 100;
            setIsUserScrolled(!isNearBottom);
            setShowScrollToBottom(!isNearBottom && scrollHeight > clientHeight + 50);
        }
    };

    const [isMobile, setIsMobile] = useState(window.innerWidth <= 768);
    useEffect(() => {
        const handleResize = () => setIsMobile(window.innerWidth <= 768);
        window.addEventListener('resize', handleResize);
        return () => window.removeEventListener('resize', handleResize);
    }, []);

    const handleKeyDown = (e) => {
        if (e.key === 'Enter' && !e.shiftKey) { e.preventDefault(); handleSendMessage(); }
    };

    const openModal = () => setIsModalOpen(true);
    const closeModal = () => setIsModalOpen(false);

    const showNotification = (message) => {
        setNotification(message);
        setTimeout(() => setNotification(null), 2500);
    };

    const ChatHeader = () => (
        <header className={currentMode.headerClass}>
            <div className={currentMode.logoClass}>
                <div className={currentMode.logoIconClass}><FontAwesomeIcon icon={currentMode.icon} /></div>
                <span className={currentMode.logoTextClass}>{currentMode.name}</span>
                <div className={`${currentMode.subscriptionBadgeClass} ${subscription}`}>{subscription} Tier {subscription === "free" && `(${remainingInteractions} left)`}</div>
            </div>
            <div className={currentMode.controlsClass}>
                
            </div>
        </header>
    );

    const ScrollToBottomButton = () => (
        showScrollToBottom && (<button className="scroll-to-bottom visible" onClick={scrollToBottom} aria-label="Scroll to newest messages" title="Scroll to bottom"><FontAwesomeIcon icon={faChevronDown} /></button>)
    );

    


    return (
        <>
            <button onClick={openModal} className={`chat-open-button ${currentMode.buttonClass} ${isModalOpen ? 'hidden' : ''}`}>
                <FontAwesomeIcon icon={currentMode.icon} style={{ marginRight: '8px' }} />
                {currentMode.buttonText}
            </button>

            {isModalOpen && (
                <div className={currentMode.modalClass}>
                    <div className={currentMode.modalContentClass}>
                        <div className={`chat-wrapper ${currentMode.containerClass} ${theme}`}>
                            <button onClick={closeModal} className={currentMode.closeButtonClass} aria-label="Close Chat" title="Close Chat">
                                <FontAwesomeIcon icon={faTimes} />
                            </button>
                            <ChatHeader />
                            {error && <div className={`chat-error-display ${currentMode.errorMessageClass}`}>{error}</div>}

                            <main className={currentMode.messagesClass} ref={messagesContainerRef} onScroll={handleScroll} aria-live="polite">
                                {messages?.map((msg, index) => (
                                    <div key={index} className={`${currentMode.messageClass} ${msg.role}`}>
                                        <div className={currentMode.messageBubbleClass}>
                                            {msg.role === 'model' && (<FontAwesomeIcon icon={currentMode.icon} className="message-icon model-icon" />)}
                                            <div className="message-text">
                                                {msg.text && (
                                                    <ReactMarkdown
                                                        remarkPlugins={[remarkGfm, remarkMath]}
                                                        rehypePlugins={[rehypeKatex]}
                                                    >
                                                        {msg.text}
                                                    </ReactMarkdown>
                                                )}
                                            </div>
                                            {msg.type === 'image_response' && msg.imageUrl && (
                                                <div className="message-image-container">
                                                    <img src={msg.imageUrl} alt={msg.text || `Generated Visual`} className="generated-image" />
                                                </div>
                                            )}
                                            {msg.role === 'model' && (msg.text || msg.imageUrl) && (
                                                <button
                                                    className={`message-action-button ${currentMode.buttonClass}--icon`}
                                                    onClick={() => handleCopyResponse(msg)}
                                                    aria-label={currentMode.copyTooltip}
                                                    title={currentMode.copyTooltip} >
                                                    <FontAwesomeIcon icon={currentMode.copyIcon} />
                                                </button>
                                            )}
                                        </div>
                                    </div>
                                ))}
                                <div ref={messagesEndRef} />
                            </main>

                            <ScrollToBottomButton />

                            {loading && (
                                <div className={`chat-loading-indicator ${currentMode.loaderClass}`}>
                                    <FontAwesomeIcon icon={faSpinner} spin />{' '}
                                    {isGeneratingImage ? "Generating visual, please wait..." : "Thinking..."}
                                </div>
                            )}
                            {subscription === "free" && remainingInteractions <= 0 && !loading && (
                                <div className={`chat-limit-message ${currentMode.errorMessageClass}`}>
                                    Interaction limit reached. {currentMode.outOfCreditsMessage}
                                </div>
                            )}
                           <footer className={`chat-footer ${currentMode.footerClass}`}>
                                <input type="file" ref={fileInputRef} style={{ display: 'none' }} onChange={handleFileChange} accept="image/*" />
                                <button className={`${currentMode.buttonClass} ${currentMode.buttonClass}--icon`} onClick={triggerFileInput} aria-label="Attach file" title="Attach image file" disabled={loading || (subscription === "free" && remainingInteractions <= 0)}>
                                    <FontAwesomeIcon icon={faPaperclip} />
                                </button>
                                <button className={`${currentMode.buttonClass} ${currentMode.buttonClass}--icon`} onClick={toggleNotepad} aria-label="Open virtual notepad" title="Open virtual notepad (Coming Soon)" disabled={loading || (subscription === "free" && remainingInteractions <= 0)}>
                                    <FontAwesomeIcon icon={faPencilAlt} />
                                </button>
                                <textarea
                                    ref={inputRef}
                                    className={currentMode.inputClass}
                                    value={userInput}
                                    onChange={(e) => setUserInput(e.target.value)}
                                    onKeyDown={handleKeyDown}
                                    onPaste={handlePaste}
                                    placeholder={fileAttachment ? `Describe ${fileAttachment.name || 'Pasted Image'}...` : currentMode.placeholder}
                                    rows="1"
                                    aria-label="Chat input"
                                    disabled={loading || (subscription === "free" && remainingInteractions <= 0)}
                                />
                                {fileAttachment && (<span className="file-attachment-name">{fileAttachment.name || 'Pasted Image'}</span>)}
                                <button
                                    className={`${currentMode.sendButtonClass} ${currentMode.buttonClass}--icon`}
                                    onClick={handleSendMessage}
                                    disabled={(!userInput.trim() && !fileAttachment) || loading || (subscription === "free" && remainingInteractions <= 0)}
                                    aria-label="Send message" title="Send message" >
                                    <FontAwesomeIcon icon={faPaperPlane} />
                                </button>
                            </footer>

                            {isNotepadOpen && (
                                <div className="virtual-notepad-placeholder" style={{ padding: '1rem', borderTop: `1px solid ${theme === 'dark' ? '#444' : '#ddd'}`, background: theme === 'dark' ? '#222' : '#f9f9f9', color: theme === 'dark' ? '#fff' : '#333' }}>
                                    Virtual Notepad Area (Implement Canvas Here)
                                    <button onClick={toggleNotepad} style={{ marginLeft: '1rem', padding: '0.3rem 0.6rem' }}>Close</button>
                                </div>
                            )}

                            {notification && (<div className="chat-notification">{notification}</div>)}
                        </div>
                    </div>
                </div>
            )}
        </>
    );
};

export default StemChat;